---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a second-year PhD student at the [University of Bristol](https://www.bristol.ac.uk/), supervised by [Prof. Shawn Shen](https://shawnshenjx.github.io/).

My research focuses on **video understanding**, **multimodal large language models (MLLMs)**, and **efficient multimodal reasoning**.

---

## ðŸ“¢ News

- **Jan 2026** â€” One paper accepted at **ICLR 2026**
- **Oct 2025** â€” Two papers accepted at **WACV 2026**
- **Jun 2025** â€” One paper accepted at **MICCAI 2025**
- **May 2025** â€” Joined [Memories.ai Research](https://memories.ai/) as an **AI Research Scientist**
- **Nov 2024** â€” ðŸŽ“ Joined the VI Lab at Bristol as a PhD student

---

## ðŸ“š Publications

### 2026

<span style="color:green">(WACV 2026)</span> **PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications**  
*Yunze Liu, Zifan Wang, **Peiran Wu**, Jiayang Ao*  
[Paper](https://arxiv.org/abs/2512.01383) | [Code](#) | [Project](#)

---

<span style="color:green">(ICLR 2026)</span> **MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding**  
***Peiran Wu**, Zhuorui Yu, Yunze Liu, Chi-Hao Wu, Enmin Zhou, Junxiao Shen*  
[Paper](https://arxiv.org/abs/2510.07915) | [Code](https://github.com/Gimlettt/MARC) | [Project](https://yunzeliu.github.io/MARC/)

---
 
<span style="color:green">(WACV 2026)</span> **St-Think: How Multimodal Large Language Models Reason About 4D Worlds from Egocentric Videos**  
***Peiran Wu**, Yunze Liu, Miao Liu, Junxiao Shen*  
[Paper](https://arxiv.org/abs/2503.12542) | [Code](https://github.com/WPR001/Ego-ST)

---
  
<span style="color:green">(MICCAI 2025)</span> **Motion-Boundary-Driven Unsupervised Surgical Instrument Segmentation in Low-Quality Optical Flow**  
*Yang Liu, **Peiran Wu**, Jiayu Huo, Gongyu Zhang, Zhen Yuan, Christos Bergeles, Rachel Sparks, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin*  
[Paper](https://link.springer.com/chapter/10.1007/978-3-032-05114-1_36) | [Code](#)

---

### Preprints

**UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks**  
***Peiran Wu**, Yunze Liu, Zhengdong Zhu, Enmin Zhou, Junxiao Shen*   
[arXiv](https://arxiv.org/abs/2507.11336) | [Code](https://github.com/WPR001/UGC_VideoCaptioner) | [Dataset](https://huggingface.co/collections/Memories-ai/ugc-videocap)

---

**VideoMAP: Toward Scalable Mamba-based Video Autoregressive Pretraining**  
*Yunze Liu, **Peiran Wu**, Cheng Liang, Junxiao Shen, Limin Wang, Li Yi*  
[arXiv](https://arxiv.org/abs/2503.12332) | [Code](#)

---

**FM-Bench: Benchmarking Fairness in Multimodal Large Language Models on Medical Tasks**  
***Peiran Wu**, Che Liu, Canyu Chen, Jun Li, Cosmin I Bercea, Rossella Arcucci*   
[arXiv](https://arxiv.org/abs/2410.01089) | [Code](#)

---


## ðŸŽ“ Education

**University of Bristol, UK**  
PhD in Computer Science  
*Oct 2024 â€“ Present*

---

## ðŸ’¼ Experience

**Memories.ai Research, USA**  
AI Research Scientist(Part-time)  
*May 2025 â€“ Present*

**Toshiba Research Europe Limited, UK**  
Research Intern  
*Jun 2024 â€“ Sep 2024*

---



<a href="https://info.flagcounter.com/QLQY"><img src="https://s01.flagcounter.com/map/QLQY/size_s/txt_000000/border_CCCCCC/pageviews_0/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>



